{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load source_extracting.py\n",
    "import numpy as np\n",
    "import sep\n",
    "from astropy.io import fits\n",
    "import matplotlib.path as mplpath\n",
    "import pylab as plt\n",
    "\n",
    "radii = [5.0, 15.0]\n",
    "\n",
    "def extract_sources(data):\n",
    "#\tdata = data.byteswap(True).newbyteorder()\n",
    "\tbkg = sep.Background(data)\n",
    "\tback = bkg.back()\n",
    "\tdata_woback = data-back\n",
    "\tthresh = 1.5 * bkg.globalrms\n",
    "\tobjects = sep.extract(data_woback, thresh)\n",
    "\treturn objects\n",
    "\n",
    "def aperture_photometry(data, objects, radii):\n",
    "\t#TODO aperture corrected flux: take the ratio of the Flux in the bigger to the flux in the smaller, average them to find the correction, then multiply each of the smaller fluxes to the correction. Do the same thing for errors. Depending on what you set your GAIN to be, this is either background only or background and Poisson. If GAIN is set to 0 its only background error. http://www.galex.caltech.edu/researcher/techdoc-ch5.html Or you could use the apertures in Figure 1... The value for the correction shouldn't change much for GALEX since the PSF doesn't change across the CCDs.\n",
    "\tflux_min, fluxerr_min, flag_min = sep.sum_circle(data, objects[0], objects[1], min(radii))\n",
    "\tflux_max, fluxerr_max, flag_max = sep.sum_circle(data, objects[0], objects[1], max(radii))\n",
    "\treturn flux_min\n",
    "\n",
    "def point_in_rect(points,vertices):\n",
    "\tnew_objects  = np.ones((len(vertices)), dtype=bool)\n",
    "\tfor i in range(len(vertices)): #iterate through each of the new objects\n",
    "\t\trect = mplpath.Path(vertices[i])\t#draw the rectangle defining it\n",
    "\t\tinside = any(rect.contains_points(points)) #check if there is already a source there\n",
    "\t\tnew_objects[i] = ~inside\n",
    "\treturn new_objects\n",
    "\n",
    "def vertices_of_pixels(xmins, xmaxs, ymins, ymaxs):\n",
    "\tverts = [[(xmins[i],ymins[i]), (xmaxs[i],ymins[i]), (xmaxs[i],ymaxs[i]), (xmins[i],ymaxs[i])] for i in range(len(xmaxs))]\n",
    "\treturn verts\n",
    "   \n",
    "def plot_frame(data_array,known_objects,xs,ys,num,pngout):\n",
    "\tplt.figure(1)\n",
    "\tplt.imshow(data_array)\n",
    "\tfor i in range(len(known_objects)):\n",
    "\t\tplt.plot(known_objects[i][0],known_objects[i][1],'ro')\n",
    "\tfor i in range(len(xs)):\n",
    "\t\tplt.plot(xs[i],ys[i],'ko')\n",
    "\tplt.savefig(pngout)\n",
    "\tplt.clf()\n",
    "\treturn\n",
    "\n",
    "def find_all_objects(framecube, bad_frame_mask, frame_wcs, pngout):\n",
    "\tall_extracted_objects = np.array([])\n",
    "\tfor i in range(framecube.shape[0]):\n",
    "\t\tobjects = extract_sources(framecube[i,:,:])\n",
    "\t\tplot_frame(framecube[i,:,:],all_extracted_objects,objects['x'],objects['y'],str(i),pngout)\n",
    "\t\tif len(objects) > 0:\n",
    "\t\t\tif len(all_extracted_objects) > 0:\n",
    "\t\t\t\tvertices = vertices_of_pixels(objects['xmin'], objects['xmax'], objects['ymin'], objects['ymax'])\n",
    "\t\t\t\tnew_objects = point_in_rect(all_extracted_objects,vertices) #returns array of True and False\n",
    "\t\t\t\tprint new_objects\n",
    "\t\t\t\tall_extracted_objects = np.vstack((all_extracted_objects, np.asarray([objects['x'][new_objects],objects['y'][new_objects]]).T))\n",
    "\t\t\telse:\n",
    "\t\t\t\tall_extracted_objects = np.asarray([objects['x'],objects['y']]).T\n",
    "\t\t#print \"total number of objects: \", len(all_extracted_objects)\n",
    "\treturn all_extracted_objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load find_transients.py\n",
    "import argparse\n",
    "from diff_image import diff_image\n",
    "from source_extracting import find_all_objects\n",
    "import numpy\n",
    "import os\n",
    "from astropy import wcs\n",
    "\n",
    "def find_transients(ifile, pngout, showplot=False):\n",
    "    # Call diff_image to get the difference image frame and a numpy mask of\n",
    "    # frames to ignore due to a lack of exposure time.\n",
    "    diff_frame, bad_frames, frame_wcs = diff_image(ifile, showplot=showplot)\n",
    "    # The source extraction script wants a 3-D array of (nframes,height,width).\n",
    "    diff_frame = numpy.expand_dims(diff_frame, axis=0)\n",
    "    # Identify those transient objects that stand out in the difference frame.\n",
    "    detected_sources_pix = find_all_objects(diff_frame, bad_frames, frame_wcs,\n",
    "                                        pngout)\n",
    "    # The WCS in the frame is 3D, but the 3rd dimension is useless, so just\n",
    "    # stick zeroes everywhere.\n",
    "    detected_sources_coords = frame_wcs.wcs_pix2world(\n",
    "        numpy.insert(detected_sources_pix,2,0.,axis=1),1)[:,0:2]\n",
    "\n",
    "    print \"Sources Found: (xpix, ypix, RA, DEC)\"\n",
    "    for pix,coord in zip(detected_sources_pix,detected_sources_coords):\n",
    "        print pix[0], pix[1], coord[0], coord[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load diff_image.py\n",
    "import argparse\n",
    "import os\n",
    "from astropy.io import fits\n",
    "from astropy import wcs\n",
    "import ipdb\n",
    "import matplotlib.pyplot as pyp\n",
    "import numpy\n",
    "\n",
    "def diff_image(ifile,showplot=False):\n",
    "    with fits.open(ifile) as hdulist:\n",
    "        frame_cube = hdulist[0].data\n",
    "        frame_wcs = wcs.WCS(hdulist[0].header)\n",
    "\n",
    "    # Parameters of the cube are (n_frames, height, width) when calling\n",
    "    # \".shape\" on the object.\n",
    "    n_frames = frame_cube.shape[0]\n",
    "    # These are the sum of all the flux across each frame.\n",
    "    tot_counts = numpy.asarray([frame_cube[x].sum() for x in\n",
    "                                xrange(n_frames)])\n",
    "    median_tot_counts = numpy.median(tot_counts)\n",
    "    mean_tot_counts = numpy.mean(tot_counts)\n",
    "    \n",
    "    # Play around with using the Median Absolute Deviation to define the\n",
    "    # base level.  Note that in order to translate the MAD into an\n",
    "    # approximation for sigma, one must use a scale factor.  For Gaussian\n",
    "    # distributions this is ~1.4826, for uniform distributions this is\n",
    "    # ~1.1547.  This is really only true for LARGE samples from a uniform\n",
    "    # distribution, but maybe it doesn't impact the outlier identification\n",
    "    # when the samples are a few 10s of frames.\n",
    "    scale_factor = 1.1547\n",
    "    mad_value = scale_factor*numpy.median(numpy.absolute(\n",
    "            tot_counts - median_tot_counts))\n",
    "    \n",
    "    # Only consider those frames with reasonable total counts, to ignore\n",
    "    # frames with very little exposure for their bin.\n",
    "    bad_frames = numpy.asarray([x < median_tot_counts-3.*mad_value for x in\n",
    "                                tot_counts])\n",
    "    \n",
    "    # Plot the total flux counts for each frame and where the cutoffs are.\n",
    "    if showplot:\n",
    "        pyp.plot(range(n_frames), tot_counts, 'ko')\n",
    "        pyp.axhline(median_tot_counts, color='b')\n",
    "        pyp.axhline(median_tot_counts-3*mad_value, color='g')\n",
    "        pyp.axhline(median_tot_counts+3*mad_value, color='g')\n",
    "        pyp.plot(numpy.asarray(range(n_frames))[bad_frames],\n",
    "                 tot_counts[bad_frames], 'ro')\n",
    "        pyp.xlim([-2.,n_frames+2])\n",
    "        pyp.show()\n",
    "        \n",
    "    # This will compute the difference between the max. flux and the min.\n",
    "    # flux for each pixel across all frames in the cube, ignoring frames\n",
    "    # identified as having low exposure time.\n",
    "    diff_image = (numpy.max(frame_cube[~bad_frames],axis=0) -\n",
    "                  numpy.median(frame_cube[~bad_frames],axis=0))\n",
    "    \n",
    "    # Write the difference image to a FITS file.\n",
    "    file_splits = os.path.splitext(ifile)\n",
    "    output_file_name = file_splits[0] + \"_diff\" + file_splits[1]\n",
    "    new_hdu = fits.PrimaryHDU(diff_image)\n",
    "    new_hdulist = fits.HDUList([new_hdu])\n",
    "    new_hdulist.writeto(output_file_name, clobber=True)\n",
    "    return (diff_image, bad_frames, frame_wcs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
